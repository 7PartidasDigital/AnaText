ANALIZADO <- htmlParse(FUENTE) # Analiza el fichero HTML bajado y lo formatea
DIRECCION <- xpathSApply(ANALIZADO, "//td/a/@href") # Extrae la direcciones URL
DIRECCION1 <- grep("ebook.*?\\.TXT\\.zip", DIRECCION) #Averigua cuáles son los ficheros TXT.zip que son los que se quieren
td <- tempdir() # Crea un directorio temporal
tf <- tempfile(tmpdir = td, fileext = "zip") # Crea un lugar donde depositarlo temeporalmente
for (i in 1:length(DIRECCION1)){
download.file(url=paste("http://www.dominiopublico.es/",DIRECCION[DIRECCION1[i]],sep = ""), tf)
#download.file("http://www.dominiopublico.es/ebook/00/01/0001.TXT.zip",tf)
fname <- unzip(tf,list = T)$Name[1]
print(fname)
unzip(tf,files = fname, exdir = "GLDS", overwrite = T)
}
unlink(td)
unlink(tf)
library("XML")
theurl <- "http://www.peaklist.org/WWlists/ultras/andes1.html"
tables <- readHTMLTable(theurl)
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
df<-tables[[which.max(n.rows)]]
df<-df[3:nrow(df),c(2,3,4,7,8)]
names(df)=c("cumbre", "pais", "altura_m", "lat_geo", "lng_geo")
df1<-na.omit(df)
theurl <- "http://www.peaklist.org/WWlists/ultras/andes2.html"
tables <- readHTMLTable(theurl)
theurl <- "http://www.peaklist.org/WWlists/ultras/andes2.html"
tables <- readHTMLTable(theurl)
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
df<-tables[[which.max(n.rows)]]
df<-df[3:nrow(df),c(2,3,4,7,8)]
names(df)=c("cumbre", "pais", "altura_m", "lat_geo", "lng_geo")
df2<-na.omit(df)
theurl <- "http://www.peaklist.org/WWlists/ultras/andes3.html"
tables <- readHTMLTable(theurl)
n.rows <- unlist(lapply(tables, function(t) dim(t)[1]))
df<-tables[[which.max(n.rows)]]
df<-df[3:nrow(df),c(2,3,4,7,8)]
names(df)=c("cumbre", "pais", "altura_m", "lat_geo", "lng_geo")
df3<-na.omit(df)
df<-rbind(df1,df2,df3)
df$altura_m<-as.integer(as.character(df$altura_m))
df$lat_geo<-as.character(df$lat_geo)
df$lng_geo<-as.character(df$lng_geo)
geo2dec<-function(c) {
z<-sapply( strsplit(c, "[Âº\'\"]"), as.character )
dec<- as.numeric(z[1, ]) + as.numeric(z[3, ])/60 + as.numeric(z[4, ])/3600
if (z[1, ]=="N"||z[1, ]=="E") dec else -dec
}
df$latitude<-geo2dec(df$lat_geo)
df$longitude<-geo2dec(df$lng_geo)
library("ggmap")
map <- get_map(location = 'Chile', zoom = 4, maptype = "terrain")
andes <- ggmap(map) + geom_point(data=df, aes(x=longitude, y=latitude, colour=altura_m),
alpha = 0.6, show.legend = FALSE, size=4)
andes <- andes + scale_colour_continuous(low = "red", high = "blue", space = "Lab", guide = "colorbar")
andes
map <- get_map(location = 'Santiago, Chile', zoom = 7, maptype = "terrain")
andes <- ggmap(map) + geom_point(data=df, aes(x=longitude, y=latitude, colour=altura_m),
alpha = 0.6, show.legend = FALSE, size=10)
andes <- andes + scale_colour_continuous(low = "red", high = "blue", space = "Lab", guide = "colorbar")
andes <- andes + geom_text(data=df, aes(label=cumbre,x =longitude+.001, y = latitude),
size = 3.5, fontface=2, colour="palevioletred" , hjust = 0)
andes
library(sp)
gadm <- readRDS("~/Dropbox/MAPAS-R/ESP_adm2.rds") # Lee los datos para dibujar
Peninsula <- gadm[gadm$NAME_1!="Islas Canarias",] # Borra las canarias
Peninsula <- Peninsula[Peninsula$NAME_1!="Ceuta y Melilla",] # Borra Ceuta y Melilla
plot(Peninsula)
points(CyL.df$lng,CyL.df$lat,col=2,pch=18, cex=2)
gadm <- readRDS("~/Dropbox/MAPAS-R/ESP_adm2.rds") # Lee los datos para dibujar
Valladolid <- gadm[gadm$NAME_2=="Valladolid",] # Extrae datos Valladolid
plot(Valladolid, col="forestgreen")
gadm <- readRDS("~/Dropbox/MAPAS-R/ESP_adm2.rds") # Lee los datos para dibujar
CyL <- gadm[gadm$NAME_1=="Castilla y León",] # Extrae datos Valladolid
plot(CyL)
library(leaflet) #Carga el paquete específico
leaflet()
m <- leaflet()
m <- addTiles (m)
m <- addMarkers (m, lng=-4.114165, lat =41.596692, popup = "Peñafiel")
m
m <- addMarkers (m, lng=-3.186391, lat =41.227012, popup = "Galve")
m
m <- addMarkers (m, lng=-2.690833, lat =41.091111, popup = "Palazuelos")
m
m <- addMarkers (m, lng=-2.619100, lat =40.783603, popup = "Cifuentes")
m
m <- addMarkers (m, lng=-2.591888, lat =40.700641, popup = "Trillo")
m
m <- addMarkers (m, lng=-2.609722, lat =40.471111, popup = "Alcocer")
m
m <- addMarkers (m, lng=-2.688889, lat =40.1475, popup = "Huete")
m
m <- addMarkers (m, lng=-2.382645, lat =39.661041, popup = "Garcimuñoz")
m
m <- addMarkers (m, lng=-2.083158, lat =39.546571, popup = "Alarcón")
m
m <- addMarkers (m, lng=-1.726366, lat =38.919603, popup = "Chinchilla")
m
m <- addMarkers (m, lng=-0.860909, lat =38.631905, popup = "Villena")
m
m <- addMarkers (m, lng=-1.1300278, lat =37.986111, popup = "Murcia")
m
install.packages("tau")
install.packages(c("tidyverse", "revest"))
library(stylo)
library(tidytext)
sentiments
library(syuzhet)
library("syuzhet", lib.loc="~/Library/R/3.3/library")
detach("package:syuzhet", unload=TRUE)
install.packages(c("backports", "broom", "circlize", "digest", "dplyr", "geosphere", "ggrepel", "glue", "gridExtra", "hms", "hunspell", "lazyeval", "lubridate", "openNLPdata", "plotrix", "psych", "purrr", "Rcpp", "RcppEigen", "reshape2", "rlang", "rmarkdown", "RWekajars", "syuzhet", "tau", "tidyr", "tidyselect", "tidytext", "tidyverse", "topicmodels", "yaml"))
install.packages(c("ape", "chron", "crayon", "curl", "data.table", "devtools", "digest", "git2r", "Matrix", "mgcv", "openssl", "raster", "Rcpp", "rstudioapi", "stringi", "stylo", "tm", "withr", "yaml"), lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(mallet)
library(mallet)
library("rJava", lib.loc="~/Library/R/3.3/library")
install.packages("rJava")
library(mallet)
1:50
install.packages("udpipe")
library(udpipe)
dl <- udpipe_download_model(language = "spanish")
str(dl)
udmodel_espa <- udpipe_load_model(file = dl$file_model)
texto <- "Se me permitirá que antes de referir el gran suceso de que fui testigo, diga algunas palabras sobre mi infancia, explicando por qué extraña manera me llevaron los azares de la vida a presenciar la terrible catástrofe de nuestra marina."
x udpipe_annotate(udmodel_espa, x = texto)
x <- udpipe_annotate(udmodel_espa, x = texto)
x <- as.data.frame(x)
str(x)
table(x$upos)
table(x$lemma)
x$lemma
(paste(x, sep = " "))
(paste(x$lemma, sep = " "))
a <- paste(x$lemma, sep = " ")
a
a <- x$lemma
paste(a, sep = " ")
a
paste(a, collapse = " ")
mac <- xmlInternalTreeParse("~/Dropbox/mac.xml")
library(XML)
mac <- xmlInternalTreeParse("~/Dropbox/mac.xml")
mac <- xmlParse("~/Dropbox/mac.xml")
mac <- xmlParse("~/Dropbox/mac.xml")
mac
habla <- xpathApply(mac, 'sp')
View(habla)
habla <- xpathSApply(mac, //*[@who='DUNCAN']/sp)
habla <- xpathSApply(mac, "//*[@who='DUNCAN']/sp", xmlValue)
habla <- xpathSApply(mac, "//*[@who='Dncan']/sp", xmlValue)
habla <- xpathSApply(mac, "//*[@who='Duncan']", xmlValue)
habla
mac <- gsub("<stage>.*?</stage>", "", mac, perl =T)
texto <- mac
xmlChildren(mac)
top <- xmlRoot(mac)
xmlName(top)
xmlName(top[2])
xmlElementsByTagName(sp)
xmlElementsByTagName("sp")
xmlElementsByTagName(mac, "sp")
devtools::install_github("Jean-Baptiste-Camps/stemmatology")
library(stemmatology)
?`stemmatology-package`
data("fournival")
View(fournival)
install.packages("syuzhet")
install.packages("syuzhet")
install.packages("flatxml")
# Lee el texto.
# Usaremos Los cuatro jinetes del Apocalipsis de V. Blasco Ibáñez, pero tienes otros dos textos más
# para probar: Trafalgar de B.Pérez Galdós, y los Pazos de Ulloa de E. Pardo Bazán
texto_entrada <- readLines("~/Documents/Github/R_LINHD-18/cuatro_jinetes_apocalipsis.txt") # Pon el nombre del fichero adecuado
# Lee el texto.
# Usaremos Los cuatro jinetes del Apocalipsis de V. Blasco Ibáñez, pero tienes otros dos textos más
# para probar: Trafalgar de B.Pérez Galdós, y los Pazos de Ulloa de E. Pardo Bazán
texto_entrada <- readLines("~/Documents/Github/R-LINHD-18/cuatro_jinetes_apocalipsis.txt") # Pon el nombre del fichero adecuado
texto_unido <- paste(texto_entrada, collapse = " ") # Funde el texto e una sola cadena
texto_palabras <- unlist(strsplit(texto_unido, " ")) # Lo divide en palabras
long_maxima <- length(texto_palabras)/400 # Establece el número de páginas en que lo debe dividir
x <- seq_along(texto_palabras)
texto_paginas <- split(texto_palabras, ceiling(x/long_maxima))
# Crea las páginas
texto_paginas <- lapply(texto_paginas, function(x) paste(x, collapse = " "))
# Convierte el texto a minúsculas
texto_paginas <- tolower(as.character(unlist(texto_paginas)))
# Calcula el sentimiento
texto_nrc <- cbind(NumPag = seq_along(texto_paginas), get_nrc_sentiment(texto_paginas, language = "spanish"))
# cambia el nombre de las columnas para que sean fácilmente comprensibles
colnames(texto_nrc) <- c("NumPag","ira", "expectación","disgusto","miedo","alegría","tristeza","sorpresa","confianza","negativo","positivo")
# Convierte a números negativos la columna negativa
texto_nrc$negativo <- -texto_nrc$negativo
# Toma las columna numero de línea, positiva y negativa y crea una nueva
# tabla de tres columnas en las que los positivos y negativos están en una
# misma columna, pero guarda de donde procede cada positivo y negativo
pos_neg <- texto_nrc %>% select(NumPag, positivo, negativo) %>%
melt(id = c("NumPag"))
# renombra las columnas
names(pos_neg) <- c("NumPag", "sentimiento", "valor")
texto_nrc <- data.frame(cbind(NumPag = seq_along(texto_paginas),
sentimiento = get_sentiment(texto_paginas, method = "nrc", language = "spanish")))
# Tercer gráfico
### Cámbiese el literal de la línea 129 por el título adecuado
ggplot(data = texto_nrc, aes(x = NumPag, y = sentimiento)) +
geom_bar(stat = "identity", position = "dodge", color = "midnightblue") +
theme_minimal() +
ylab("Sentimiento") +
ggtitle(expression(paste("Sentimiento en ", italic("Los cuatro jinetes del Apocalipsis")))) +
theme(axis.title.x=element_blank()) +
theme(axis.ticks.x=element_blank()) +
theme(axis.text.x=element_blank()) +
theme(legend.justification=c(0.91,0), legend.position=c(1, 0))
library(readr)
library(stringr)
library(syuzhet)
library(dplyr)
library(reshape2)
library(ggplot2)
texto_entrada <- readLines("~/Documents/Github/R-LINHD-18/cuatro_jinetes_apocalipsis.txt") # Pon el nombre del fichero adecuado
texto_unido <- paste(texto_entrada, collapse = " ") # Funde el texto e una sola cadena
texto_palabras <- unlist(strsplit(texto_unido, " ")) # Lo divide en palabras
long_maxima <- length(texto_palabras)/400 # Establece el número de páginas en que lo debe dividir
x <- seq_along(texto_palabras)
texto_paginas <- split(texto_palabras, ceiling(x/long_maxima))
# Crea las páginas
texto_paginas <- lapply(texto_paginas, function(x) paste(x, collapse = " "))
# Convierte el texto a minúsculas
texto_paginas <- tolower(as.character(unlist(texto_paginas)))
# Calcula el sentimiento
texto_nrc <- cbind(NumPag = seq_along(texto_paginas), get_nrc_sentiment(texto_paginas, language = "spanish"))
# cambia el nombre de las columnas para que sean fácilmente comprensibles
colnames(texto_nrc) <- c("NumPag","ira", "expectación","disgusto","miedo","alegría","tristeza","sorpresa","confianza","negativo","positivo")
# Convierte a números negativos la columna negativa
texto_nrc$negativo <- -texto_nrc$negativo
# Toma las columna numero de línea, positiva y negativa y crea una nueva
# tabla de tres columnas en las que los positivos y negativos están en una
# misma columna, pero guarda de donde procede cada positivo y negativo
pos_neg <- texto_nrc %>% select(NumPag, positivo, negativo) %>%
melt(id = c("NumPag"))
# renombra las columnas
names(pos_neg) <- c("NumPag", "sentimiento", "valor")
texto_nrc <- data.frame(cbind(NumPag = seq_along(texto_paginas),
sentimiento = get_sentiment(texto_paginas, method = "nrc", language = "spanish")))
# Tercer gráfico
### Cámbiese el literal de la línea 129 por el título adecuado
ggplot(data = texto_nrc, aes(x = NumPag, y = sentimiento)) +
geom_bar(stat = "identity", position = "dodge", color = "midnightblue") +
theme_minimal() +
ylab("Sentimiento") +
ggtitle(expression(paste("Sentimiento en ", italic("Los cuatro jinetes del Apocalipsis")))) +
theme(axis.title.x=element_blank()) +
theme(axis.ticks.x=element_blank()) +
theme(axis.text.x=element_blank()) +
theme(legend.justification=c(0.91,0), legend.position=c(1, 0))
texto_ft <- as.numeric(get_transformed_values(texto_nrc$sentimiento,
low_pass_size = 3,
scale_vals = TRUE,
scale_range = FALSE))
texto_ft <- data.frame(cbind(NumPag = seq_along(texto_ft), ft = texto_ft))
ggplot(data = texto_ft, aes(x = NumPag, y = ft)) +
geom_bar(stat = "identity", alpha = 0.8, color = "aquamarine3", fill = "aquamarine3") +
theme_minimal() +
labs(title ="Forma de la historia en Los cuatro jinetes del Apocalipsis", subtitle="NRC", x = "Tiempo narrativo", y = "Transformación Valorada del Sentimiento") +
#ylab("Transformación Valorada del Sentimiento") +
#ggtitle(expression(paste("Sentimientos en ", italic("Los cuatro jinetes del Apocalipsis")))) +
#theme(axis.title.x=element_blank()) +
#theme(axis.ticks.x=element_blank()) +
#theme(axis.text.x=element_blank()) +
geom_smooth(se=FALSE) # se=FALSE borra lo gris del smooth
ficheros <- list.files("~/Dropbox/_CORPUS_BASICO/-NADAL/txt")
autor_titulo <- gsub("^(.*?)_(\d+)-.*$", "\\1", autor_titulo, perl = T)
autor_titulo <- gsub("^(.*?)_(\\d{4})-.*$", "\\1", autor_titulo, perl = T)
autor_titulo <- gsub("^(.*?)_(\\d{4})-.*$", "\\1", ficheros, perl = T)
autor_titulo <- gsub("^(.*?)_(\\d{4})_.*$", "\\1", ficheros, perl = T)
year <- gsub("^(.*?)_(\\d{4})_.*$", "\\2", ficheros, perl = T)
library(rvest)
cancion <- html("https://www.musica.com/letras.asp?letra=6515")
letra <- cancion %>%
html_node("letra") %>%
html_text()
cancion <- read_html("https://www.musica.com/letras.asp?letra=6515")
cancion <- read_html("https://www.musica.com/letras.asp?letra=6515")
letra <- cancion %>%
html_nodes(".letra") %>%
html_text()
letra <- cancion %>%
html_nodes("br") %>%
html_text()
letra
letra <- cancion %>%
html_nodes("p") %>%
html_text()
letra
letra <- cancion %>%
html_nodes(".letra div") %>%
html_text()
letra <- cancion %>%
html_nodes(".letra") %>%
html_text()
letra <- cancion %>%
html_nodes("div") %>%
html_text()
letra
letra <- cancion %>%
html_nodes(".letra+ .text_align") %>%
html_text()
letra <- cancion %>%
html_nodes(".letra+ .text-align") %>%
html_text()
cancion <- read_html("https://www.musica.com/letras.asp?letra=6515")
letra <- cancion %>%
html_nodes(".letra+ .text-align") %>%
html_text()
letra <- cancion %>%
html_nodes(".letra+ p") %>%
html_text()
letra
letra <- cancion %>%
html_nodes(".div+ .letra+") %>%
html_text()
letra <- cancion %>%
html_nodes(".div+ .letra") %>%
html_text()
letra <- cancion %>%
html_nodes(".letra+ p") %>%
html_text()
letra
cancion <- read_html("https://www.musica.com/letras.asp?letra=6515")
letra <- cancion %>%
html_nodes(".letra p") %>%
html_text()
letra <- cancion %>%
html_nodes("letra+ p") %>%
html_text()
letra <- cancion %>%
html_nodes("p") %>%
html_text()
letra <- cancion %>%
html_nodes("p") %>%
html_text()
letra
cancion <- read_html("https://www.musica.com/letras.asp?letra=67132")
letra <- cancion %>%
html_nodes("p") %>%
html_text()
letra
listado <- read.delim("https://raw.githubusercontent.com/7PartidasDigital/AnalisisTextual/master/mensajes/DISCURSOS-INDICE.txt", header = T, sep = "\t", stringsAsFactors = F)
listado
listado
nrwo(listado)
nrow(listado)
a <- installed.packages()
a
library(stylo)
stylo()
library(devtools)
install_github('andreacirilloac/updateR')
library(stylo)
install.packages("stylo", "tidyverse", "tidytext", "syuzhet")
library(tidyverse)
install.packages("stylo")
install.packages("syuzhet")
install.packages(c("tidyverse", "tidytext"))
library(tidyverse)
install.packages(c("koRpus", "koRpus.lang.es"))
install.koRpus.lang("es")
library(koRpus)
install.koRpus.lang("es")
mean(c(6.6, 6.7, 6.2, 5.7, 5.9, 6.6))
mean(c(6.7, 6.6, 6.9, 6.9))
meanc(7.4,7.2,6.4)
mean(c(7.4,7.2,6.4))
mean(c(7.2, 6.2, 6.3, 6.3))
mean(c(5.7,6.2))
mean(c(6.3,6.1))
mean(c(5.64,5.9))
mean(c(7.1,7.3,5.5,6.3,5.6,6.2))
mean(c(7.5,
6.2,
6.8,
6.4,
7,
6.4))
mean(c(7.1,7.2,6.8,6.5,6.1))
mean(c(6.9,6.7,6.7,7.2))
mean(c(6.9,6.6,7,6.9))
mean(c(7.2,7.2,6.9))
mean(c(7.8,7.4,6.5))
mean(c(7,5.9,6.6,7.2))
mean(c(7.4,6,6.5,6.9))
mean(c(5.4,5.6,5.9))
mean(c(5.9,6,5.9))
mean(c(7.3,7.5,7.2,8.5,7.8,7.5,7.3))
mean(c(7.2,7.4,7.1,8.4,7.4,7.2,7.1))
mean(c(7.3,6.1,7.1,6.8,7.7))
mean(c(6.4,6.4,6.6,7.5,5.8,7.4))
mean(c(7.7,6.7,6.6,7.7,6.5,7.7))
median(c(6.2,6.1,6.1,6))
mean(c(6.2,6.1,6.1,6))
mean(c(6.8, 6.5, 5.6, 6.1, 6, 6.4))
mean(c(6.7, 6.6, 6.9, 6.9))
mean(c(6.3, 6.4, 6.8, 6.6))
mean(c(6.9,6.8,5.9))
mean(c(7.3,6.2,6.6,7))
mean(c(6.1,5.8,5.8))
mean(c(6.8,6.9,6.9,7.9,7.4,7.4,7.1))
mean(c(6.2,7.3,5.5,7))
setwd("~/Documents/Github/AnaText")
library(tidyverse)
library(tidytext)
ficheros <- list.files(path = "datos/mensajes", pattern = "*.txt")
ficheros <- ficheros[33:76]
anno <- gsub("\\.txt", "", ficheros, perl = T)
mensajes <- data_frame(anno = character(),
parrafo = numeric(),
texto = character())
for (i in 1:length(ficheros)){
discurso <- readLines(paste("datos/mensajes", ficheros[i], sep = "/"))
temporal <- data_frame(anno = anno[i], parrafo = seq_along(discurso), texto = discurso)
mensajes <- bind_rows(mensajes, temporal)
}
mensajes_palabras <- mensajes %>%
unnest_tokens(palabra, texto)
mensajes_frecuencias <- mensajes_palabras %>%
count(palabra, sort = T) %>%
mutate(relativa = n / sum(n))
frecuencias_anno <- mensajes_palabras %>%
group_by(anno) %>%
count(palabra, sort =T) %>%
mutate(relativa = n / sum(n)) %>%
ungroup()
palabras_1992 <- frecuencias_anno %>%
filter(anno == "1992")
# Carga las librerías
library(tidyverse)
library(tidytext)
# Ahora cargará todos los ficheros de los mensajes
ficheros <- list.files(path ="datos/mensajes", pattern = "\\d+")
ficheros <- ficheros[33:76]
anno <- gsub("\\.txt", "", ficheros, perl = T)
mensajes <- data_frame(anno = character(), parrafo = numeric(), texto = character())
for (i in 1:length(ficheros)){
discurso <- readLines(paste("datos/mensajes", ficheros[i], sep = "/"))
temporal <- data_frame(anno = anno[i], parrafo = seq_along(discurso), texto = discurso)
mensajes <- bind_rows(mensajes, temporal)
}
# Regenera la tabla general con todas las palabras
mensajes_palabras <- mensajes %>%
unnest_tokens(palabra, texto)
# Crea la tabla con todas las palabras y calcula frecuencias
mensajes_frecuencias <- mensajes_palabras %>%
count(palabra, sort = T) %>%
mutate(relativa = n / sum(n))
# Borra objetos que no sirven y que son temporales
rm(temporal,discurso,i)
# Palabras vacías de "diseño"
vacias <- as_tibble(read.delim("https://raw.githubusercontent.com/7PartidasDigital/AnaText/master/datos/vacias.txt",
header= TRUE,
quote = '"',
encoding = "UTF-8",
stringsAsFactors = F))
mensajes_vaciado <- mensajes_palabras %>%
anti_join(vacias)
mensajes_vaciado %>%
count(palabra, sort = T)
mensajes_vaciado %>%
count(palabra, sort = T) %>%
filter(n > 65) %>%
mutate(palabra = reorder(palabra, n)) %>%
ggplot(aes(x = palabra, y = n, fill = palabra)) +
geom_bar(stat="identity") +
theme_minimal() +
theme(legend.position = "none") +
ylab("Número de veces que aparecen") +
xlab(NULL) +
ggtitle("Mensajes de Navidad") +
coord_flip()
mensajes_vaciado <- mensajes_vaciado %>%
mutate(rey = anno) %>%
mutate(rey = str_replace(rey, "201[45678]", "Felipe VI")) %>%
mutate(rey = str_replace(rey, "\\d+", "Juan Carlos I"))
mensajes_vaciado %>%
group_by(rey) %>%
count(palabra, sort = T) %>%
top_n(10)
mensajes_vaciado %>%
group_by(rey) %>%
count(palabra, sort = T) %>%
top_n(10) %>%
ggplot(aes(reorder(palabra, n), n, fill = rey)) +
geom_bar(stat = "identity") +
facet_wrap(~rey, scales = "free_y") +
labs(x = "", y = "Frecuencia") +
coord_flip() +
theme(legend.position="none")
mensaje_anno <- mensajes_vaciado %>%
select(rey, anno, palabra) %>%
group_by(anno) %>%
count(palabra, sort =T) %>%
ungroup()
mensaje_anno <- mensajes_vaciado %>%
select(rey, anno, palabra) %>%
filter(rey == "Felipe VI") %>%
group_by(anno) %>%
count(palabra, sort =T) %>%
ungroup()
mensaje_anno %>%
filter(n > 5) %>%
ggplot(aes(x = palabra, y = n)) +
geom_col(fill = "aquamarine") +
coord_flip() +
facet_wrap(~ anno, ncol = 3, scales = "free_y")
